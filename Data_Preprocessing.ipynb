{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install scikit-learn\n",
    "#!conda update scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze and clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./dataset/exoplanet_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6991, 41)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all the columns where all the values are null\n",
    "df = df.dropna(axis = \"columns\", how =\"all\")\n",
    "# drop all the rows where all the values are null\n",
    "df = df.dropna(axis = \"rows\", how = \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6991, 41)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6991 entries, 0 to 6990\n",
      "Data columns (total 41 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   koi_disposition    6991 non-null   object \n",
      " 1   koi_fpflag_nt      6991 non-null   int64  \n",
      " 2   koi_fpflag_ss      6991 non-null   int64  \n",
      " 3   koi_fpflag_co      6991 non-null   int64  \n",
      " 4   koi_fpflag_ec      6991 non-null   int64  \n",
      " 5   koi_period         6991 non-null   float64\n",
      " 6   koi_period_err1    6991 non-null   float64\n",
      " 7   koi_period_err2    6991 non-null   float64\n",
      " 8   koi_time0bk        6991 non-null   float64\n",
      " 9   koi_time0bk_err1   6991 non-null   float64\n",
      " 10  koi_time0bk_err2   6991 non-null   float64\n",
      " 11  koi_impact         6991 non-null   float64\n",
      " 12  koi_impact_err1    6991 non-null   float64\n",
      " 13  koi_impact_err2    6991 non-null   float64\n",
      " 14  koi_duration       6991 non-null   float64\n",
      " 15  koi_duration_err1  6991 non-null   float64\n",
      " 16  koi_duration_err2  6991 non-null   float64\n",
      " 17  koi_depth          6991 non-null   float64\n",
      " 18  koi_depth_err1     6991 non-null   float64\n",
      " 19  koi_depth_err2     6991 non-null   float64\n",
      " 20  koi_prad           6991 non-null   float64\n",
      " 21  koi_prad_err1      6991 non-null   float64\n",
      " 22  koi_prad_err2      6991 non-null   float64\n",
      " 23  koi_teq            6991 non-null   int64  \n",
      " 24  koi_insol          6991 non-null   float64\n",
      " 25  koi_insol_err1     6991 non-null   float64\n",
      " 26  koi_insol_err2     6991 non-null   float64\n",
      " 27  koi_model_snr      6991 non-null   float64\n",
      " 28  koi_tce_plnt_num   6991 non-null   int64  \n",
      " 29  koi_steff          6991 non-null   int64  \n",
      " 30  koi_steff_err1     6991 non-null   int64  \n",
      " 31  koi_steff_err2     6991 non-null   int64  \n",
      " 32  koi_slogg          6991 non-null   float64\n",
      " 33  koi_slogg_err1     6991 non-null   float64\n",
      " 34  koi_slogg_err2     6991 non-null   float64\n",
      " 35  koi_srad           6991 non-null   float64\n",
      " 36  koi_srad_err1      6991 non-null   float64\n",
      " 37  koi_srad_err2      6991 non-null   float64\n",
      " 38  ra                 6991 non-null   float64\n",
      " 39  dec                6991 non-null   float64\n",
      " 40  koi_kepmag         6991 non-null   float64\n",
      "dtypes: float64(31), int64(9), object(1)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we can conclude that there are no NULL values present inside the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are converting the multivariate classes into numeric labels using label encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset into train - test datasets, and storing them as .csv file in the folder 'dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5592, 40) (1399, 40)\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "y = df[\"koi_disposition\"]\n",
    "x = df.drop(columns = [\"koi_disposition\"])\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = pd.DataFrame(encoder.fit(y).transform(y))\n",
    "y_encoded.columns = [\"koi_disposition\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, random_state = 1, stratify = y_encoded, \\\n",
    "                                                    train_size = 0.8)\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(type(x_train), type(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the data using MinMaxScaler with feature range = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "#\n",
    "# Transform numpy ndarray to pandas dataframe\n",
    "#\n",
    "x_train = pd.DataFrame(x_train)\n",
    "x_test = pd.DataFrame(x_test)\n",
    "#\n",
    "# Resetting the index values\n",
    "#\n",
    "x_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "x_test.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training examples is - (5592, 40) and the shape of the test examples is - (1399, 40)\n",
      "The type of the training examples is - <class 'pandas.core.frame.DataFrame'> and the type of the test examples is - <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the training examples is - {0} and the shape of the test examples is - {1}\".format\\\n",
    "      (x_train.shape, x_test.shape))\n",
    "print(\"The type of the training examples is - {0} and the type of the test examples is - {1}\".format\\\n",
    "      (type(x_train), type(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate the labels and the examples into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frames = [x_train, y_train]\n",
    "test_frames = [x_test, y_test]\n",
    "train_data = pd.concat(train_frames, axis = 1)\n",
    "test_data = pd.concat(test_frames, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the train data is - (5592, 41) and the shape of the test data is - (1399, 41)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the train data is - {0} and the shape of the test data is - {1}\".format\\\n",
    "      (train_data.shape, test_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the training data and test data as .csv file into the folder dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(\"./dataset/train_dataset.csv\", index=False)\n",
    "test_data.to_csv(\"./dataset/test_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
